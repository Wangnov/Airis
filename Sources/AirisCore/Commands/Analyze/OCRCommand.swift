import ArgumentParser
@preconcurrency import Vision
import Foundation

struct OCRCommand: AsyncParsableCommand {
    static var configuration: CommandConfiguration {
        CommandConfiguration(
        commandName: "ocr",
        abstract: HelpTextFactory.text(
            en: "Extract text from images (OCR)",
            cn: "ä»å›¾ç‰‡ä¸­æå–æ–‡å­—ï¼ˆOCRï¼‰"
        ),
        discussion: helpDiscussion(
            en: """
                Recognize and extract text from images using Apple's Vision \
                framework. Supports multiple languages including Chinese and English.

                QUICK START:
                  airis analyze ocr document.jpg

                EXAMPLES:
                  # Extract text from image
                  airis analyze ocr screenshot.png

                  # Specify languages (Chinese + English)
                  airis analyze ocr doc.jpg --languages zh-Hans,en

                  # Fast mode (less accurate but faster)
                  airis analyze ocr photo.png --level fast

                  # JSON output for scripting
                  airis analyze ocr image.heic --format json

                  # Extract text with bounding boxes
                  airis analyze ocr scan.jpg --show-bounds

                OUTPUT FORMAT (table):
                  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                  ğŸ“ æ–‡å­—è¯†åˆ« (OCR)
                  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                  ğŸ“ æ–‡ä»¶: document.jpg
                  ğŸŒ è¯­è¨€: zh-Hans, en
                  âš¡ è¯†åˆ«çº§åˆ«: accurate
                  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

                  è¯†åˆ«åˆ° 5 æ®µæ–‡å­—

                  [1] Hello World
                  [2] ä½ å¥½ä¸–ç•Œ
                  [3] Welcome to Airis
                  ...

                OPTIONS:
                  --languages <list>    Comma-separated language codes
                                        (default: zh-Hans,en)
                  --level <mode>        Recognition level: fast, accurate
                                        (default: accurate)
                  --format <type>       Output format: table, json, text
                                        (default: table)
                  --show-bounds         Show bounding box coordinates

                SUPPORTED LANGUAGES:
                  en (English), zh-Hans (Simplified Chinese), zh-Hant (Traditional Chinese),
                  ja (Japanese), ko (Korean), de (German), fr (French), es (Spanish),
                  pt (Portuguese), it (Italian), ru (Russian), and more.

                NOTES:
                  - Uses VNRecognizeTextRequest from Apple Vision framework
                  - All processing is done locally on device
                  - 'accurate' level provides better results but is slower
                  - Language correction is enabled by default
                """,
            cn: """
                ä½¿ç”¨ Apple Vision çš„æ–‡æœ¬è¯†åˆ«èƒ½åŠ›ä»å›¾ç‰‡ä¸­æå–æ–‡å­—ï¼ˆOCRï¼‰ã€‚
                æ”¯æŒä¸­è‹±æ–‡ç­‰å¤šè¯­è¨€ã€‚

                QUICK START:
                  airis analyze ocr document.jpg

                EXAMPLES:
                  # ä»å›¾ç‰‡æå–æ–‡å­—
                  airis analyze ocr screenshot.png

                  # æŒ‡å®šè¯­è¨€ï¼ˆç®€ä½“ä¸­æ–‡ + è‹±æ–‡ï¼‰
                  airis analyze ocr doc.jpg --languages zh-Hans,en

                  # å¿«é€Ÿæ¨¡å¼ï¼ˆé€Ÿåº¦æ›´å¿«ï¼Œç²¾åº¦æ›´ä½ï¼‰
                  airis analyze ocr photo.png --level fast

                  # JSON è¾“å‡ºï¼ˆä¾¿äºè„šæœ¬è§£æï¼‰
                  airis analyze ocr image.heic --format json

                  # è¾“å‡ºæ–‡å­—åæ ‡æ¡†
                  airis analyze ocr scan.jpg --show-bounds

                OPTIONS:
                  --languages <list>    è¯­è¨€ä»£ç åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼Œé»˜è®¤ï¼šzh-Hans,enï¼‰
                  --level <mode>        è¯†åˆ«çº§åˆ«ï¼šfast / accurateï¼ˆé»˜è®¤ï¼šaccurateï¼‰
                  --format <type>       è¾“å‡ºæ ¼å¼ï¼štable / json / textï¼ˆé»˜è®¤ï¼štableï¼‰
                  --show-bounds         è¾“å‡º bounding box åæ ‡

                è¯´æ˜ï¼š
                  - å…¨éƒ¨æœ¬åœ°æ‰§è¡Œï¼ˆä¸ä¸Šä¼ å›¾ç‰‡ï¼‰
                  - accurate æ›´æ…¢ä½†æ›´å‡†
                """
        )
    )
    }

    @Argument(help: HelpTextFactory.help(en: "Path to the image file", cn: "è¾“å…¥å›¾ç‰‡è·¯å¾„"))
    var imagePath: String

    @Option(name: .long, help: HelpTextFactory.help(en: "Comma-separated language codes (default: zh-Hans,en)", cn: "è¯­è¨€ä»£ç åˆ—è¡¨ï¼ˆé€—å·åˆ†éš”ï¼Œé»˜è®¤ï¼šzh-Hans,enï¼‰"))
    var languages: String = "zh-Hans,en"

    @Option(
        name: .long,
        help: HelpTextFactory.help(
            en: "Recognition level: fast, accurate (default: accurate)",
            cn: "è¯†åˆ«çº§åˆ«ï¼šfast / accurateï¼ˆé»˜è®¤ï¼šaccurateï¼‰"
        )
    )
    var level: String = "accurate"

    @Option(name: .long, help: HelpTextFactory.help(en: "Output format: table (default), json, text", cn: "è¾“å‡ºæ ¼å¼ï¼štableï¼ˆé»˜è®¤ï¼‰/ json / text"))
    var format: String = "table"

    @Flag(name: .long, help: HelpTextFactory.help(en: "Show bounding box coordinates", cn: "è¾“å‡ºæ–‡å­—åæ ‡æ¡†ï¼ˆbounding boxï¼‰"))
    var showBounds: Bool = false

    func run() async throws {
        let url = try FileUtils.validateImageFile(at: imagePath)
        let vision = ServiceContainer.shared.visionService

        let outputFormat = OutputFormat.parse(format)
        let showHumanOutput = AirisOutput.shouldPrintHumanOutput(format: outputFormat)

        // è§£æè¯­è¨€åˆ—è¡¨
        let languageList = languages.split(separator: ",").map { String($0).trimmingCharacters(in: .whitespaces) }

        // è§£æè¯†åˆ«çº§åˆ«
        let recognitionLevel: VNRequestTextRecognitionLevel = level.lowercased() == "fast" ? .fast : .accurate

        AirisOutput.printBanner([
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            "ğŸ“ æ–‡å­—è¯†åˆ« (OCR)",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            "ğŸ“ æ–‡ä»¶: \(url.lastPathComponent)",
            "ğŸŒ è¯­è¨€: \(languageList.joined(separator: ", "))",
            "âš¡ è¯†åˆ«çº§åˆ«: \(level.lowercased())",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        ], enabled: showHumanOutput)

        #if DEBUG
        // æµ‹è¯•/è°ƒè¯•ç¯å¢ƒä¸‹å¯æ³¨å…¥æ¡©ç»“æœï¼Œè¦†ç›–ä½ç½®ä¿¡åº¦ä¸åæ ‡åˆ†æ”¯
        if ProcessInfo.processInfo.environment["AIRIS_FORCE_OCR_FAKE"] == "1" {
            let fakeResults = [
                TextResult(text: "ä½ç½®ä¿¡åº¦", confidence: 0.42, boundingBox: CGRect(x: 0.1, y: 0.2, width: 0.3, height: 0.25)),
                TextResult(text: "é«˜ç½®ä¿¡åº¦", confidence: 0.95, boundingBox: CGRect(x: 0.55, y: 0.6, width: 0.2, height: 0.15))
            ]
            handleResults(fakeResults, outputFormat: outputFormat, showHumanOutput: showHumanOutput)
            return
        }
        #endif

        // æ‰§è¡Œ OCR
        let results = try await vision.recognizeText(
            at: url,
            languages: languageList,
            level: recognitionLevel
        )

        let textResults = extractTextResults(from: results)
        handleResults(textResults, outputFormat: outputFormat, showHumanOutput: showHumanOutput)
    }

    private func extractTextResults(from observations: [VNRecognizedTextObservation]) -> [TextResult] {
        observations.compactMap { observation -> TextResult? in
            guard let topCandidate = observation.topCandidates(1).first else { return nil }

            let boundingBox = observation.boundingBox

            return TextResult(
                text: topCandidate.string,
                confidence: topCandidate.confidence,
                boundingBox: boundingBox
            )
        }
    }

    private func handleResults(_ textResults: [TextResult], outputFormat: OutputFormat, showHumanOutput: Bool) {
        if textResults.isEmpty {
            switch outputFormat {
            case .json:
                printJSON(results: [])
            case .text:
                break
            case .table:
                if showHumanOutput {
                    print(Strings.get("error.no_results"))
                }
            }
            return
        }

        switch outputFormat {
        case .json:
            printJSON(results: textResults)
        case .text:
            printPlainText(results: textResults)
        case .table:
            if showHumanOutput {
                printTable(results: textResults)
            }
        }
    }

#if DEBUG
    /// æµ‹è¯•è¾…åŠ©ï¼šè¦†ç›– topCandidates ä¸ºç©ºçš„åˆ†æ”¯
    static func testExtractEmptyCandidate() -> [TextResult] {
        let obs = VNRecognizedTextObservation()
        return OCRCommand().extractTextResults(from: [obs])
    }
#endif

    private func printTable(results: [TextResult]) {
        print("è¯†åˆ«åˆ° \(results.count) æ®µæ–‡å­—")
        print("")

        for (index, result) in results.enumerated() {
            print("[\(index + 1)] \(result.text)")

            if showBounds {
                let box = result.boundingBox
                let x = String(format: "%.2f", box.origin.x)
                let y = String(format: "%.2f", box.origin.y)
                let w = String(format: "%.2f", box.width)
                let h = String(format: "%.2f", box.height)
                print("    ä½ç½®: (\(x), \(y)) å¤§å°: \(w) Ã— \(h)")
            }

            // ä»…å½“ç½®ä¿¡åº¦ä½æ—¶æ˜¾ç¤º
            if result.confidence < 0.9 {
                print("    ç½®ä¿¡åº¦: \(String(format: "%.2f", result.confidence))")
            }
        }
    }

    private func printJSON(results: [TextResult]) {
        let items = results.map { result -> [String: Any] in
            var item: [String: Any] = [
                "text": result.text,
                "confidence": result.confidence
            ]

            if showBounds {
                item["bounding_box"] = [
                    "x": result.boundingBox.origin.x,
                    "y": result.boundingBox.origin.y,
                    "width": result.boundingBox.width,
                    "height": result.boundingBox.height
                ]
            }

            return item
        }

        let dict: [String: Any] = [
            "count": results.count,
            "texts": items
        ]

        if let jsonData = try? JSONSerialization.data(withJSONObject: dict, options: [.prettyPrinted, .sortedKeys]),
           let jsonString = String(data: jsonData, encoding: .utf8) {
            print(jsonString)
        }
    }

    private func printPlainText(results: [TextResult]) {
        // çº¯æ–‡æœ¬è¾“å‡ºï¼Œé€‚åˆç®¡é“å¤„ç†
        for result in results {
            print(result.text)
        }
    }

    /// OCR è¯†åˆ«ç»“æœ
    struct TextResult {
        let text: String
        let confidence: Float
        let boundingBox: CGRect
    }
}
