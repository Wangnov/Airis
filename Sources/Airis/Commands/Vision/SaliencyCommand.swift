import ArgumentParser
@preconcurrency import Vision
import CoreImage
import Foundation

struct SaliencyCommand: AsyncParsableCommand {
    static let configuration = CommandConfiguration(
        commandName: "saliency",
        abstract: HelpTextFactory.text(
            en: "Detect visual saliency (attention areas) in images",
            cn: "æ˜¾è‘—æ€§æ£€æµ‹ï¼ˆæ³¨æ„åŠ›åŒºåŸŸï¼‰"
        ),
        discussion: helpDiscussion(
            en: """
                Generate a saliency map highlighting visually important regions.
                Supports both attention-based and objectness-based detection.

                QUICK START:
                  airis vision saliency photo.jpg

                SALIENCY TYPES:
                  attention   - Human visual attention model (where eyes look)
                               Returns 1 salient region (default)
                  objectness  - Object prominence model (likely objects)
                               Returns up to 3 salient regions

                EXAMPLES:
                  # Attention-based saliency (default)
                  airis vision saliency portrait.jpg

                  # Objectness-based saliency
                  airis vision saliency scene.jpg --type objectness

                  # Save heatmap visualization
                  airis vision saliency photo.jpg -o heatmap.png

                  # JSON output with bounding boxes
                  airis vision saliency photo.jpg --format json

                OUTPUT EXAMPLE:
                  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                  Saliency Detection
                  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                  File: portrait.jpg
                  Type: attention
                  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

                  Heatmap: 68 x 68
                  Salient regions: 1

                  Region 1:
                    Position: (0.25, 0.30)
                    Size: 0.50 x 0.40

                USE CASES:
                  - Smart cropping (crop around salient regions)
                  - Thumbnail generation
                  - Image composition analysis
                  - Focus detection

                NOTE:
                  The heatmap is a grayscale image where brighter = more salient.
                  Bounding boxes use normalized coordinates (0.0 - 1.0).
                """,
            cn: """
                ç”Ÿæˆæ˜¾è‘—æ€§çƒ­åŠ›å›¾ï¼ˆsaliency mapï¼‰ï¼Œé«˜äº®è§†è§‰ä¸Šæ›´é‡è¦/æ›´å¸å¼•æ³¨æ„åŠ›çš„åŒºåŸŸã€‚
                æ”¯æŒ attentionï¼ˆæ³¨æ„åŠ›ï¼‰ä¸ objectnessï¼ˆç‰©ä½“æ˜¾è‘—æ€§ï¼‰ä¸¤ç§æ¨¡å¼ã€‚

                QUICK START:
                  airis vision saliency photo.jpg

                EXAMPLES:
                  # é»˜è®¤ï¼šattention
                  airis vision saliency portrait.jpg

                  # objectness æ¨¡å¼
                  airis vision saliency scene.jpg --type objectness

                  # ä¿å­˜çƒ­åŠ›å›¾ï¼ˆPNGï¼‰
                  airis vision saliency photo.jpg -o heatmap.png

                  # JSON è¾“å‡ºï¼ˆåŒ…å« bounding boxesï¼‰
                  airis vision saliency photo.jpg --format json

                OPTIONS:
                  --type <type>      attention / objectness
                  --format <fmt>     è¾“å‡ºæ ¼å¼ï¼štableï¼ˆé»˜è®¤ï¼‰æˆ– json
                """
        )
    )

    @Argument(help: HelpTextFactory.help(en: "Path to image file", cn: "è¾“å…¥å›¾ç‰‡è·¯å¾„"))
    var imagePath: String

    @Option(name: .long, help: HelpTextFactory.help(en: "Saliency type (attention, objectness)", cn: "æ˜¾è‘—æ€§ç±»å‹ï¼ˆattention / objectnessï¼‰"))
    var type: String = "attention"

    @Option(name: [.short, .long], help: HelpTextFactory.help(en: "Output heatmap image path", cn: "è¾“å‡ºçƒ­åŠ›å›¾è·¯å¾„"))
    var output: String?

    @Option(name: .long, help: HelpTextFactory.help(en: "Output format (table, json)", cn: "è¾“å‡ºæ ¼å¼ï¼ˆtable / jsonï¼‰"))
    var format: String = "table"

    func run() async throws {
        let url = try FileUtils.validateImageFile(at: imagePath)
        let outputFormat = OutputFormat.parse(format)
        let showHumanOutput = AirisOutput.shouldPrintHumanOutput(format: outputFormat)

        // Parse saliency type
        let saliencyType: VisionService.SaliencyType
        switch type.lowercased() {
        case "attention":
            saliencyType = .attention
        case "objectness":
            saliencyType = .objectness
        default:
            saliencyType = .attention
        }

        if showHumanOutput {
            print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            print("ğŸ‘ï¸ Saliency Detection")
            print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            print("ğŸ“ File: \(url.lastPathComponent)")
            print("ğŸ¯ Type: \(type)")
            if let output = output {
                print("ğŸ’¾ Output: \(output)")
            }
            print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            print("")
            print("â³ Detecting saliency...")
        }

        let result: VisionService.SaliencyResult
        #if DEBUG
        if ProcessInfo.processInfo.environment["AIRIS_TEST_SALIENCY_FAKE_RESULT"] == "1" {
            result = Self.testSaliencyResult(type: saliencyType)
        } else {
            let vision = ServiceContainer.shared.visionService
            result = try await vision.detectSaliency(at: url, type: saliencyType)
        }
        #else
        let vision = ServiceContainer.shared.visionService
        result = try await vision.detectSaliency(at: url, type: saliencyType)
        #endif

        // Get original image info for coordinate conversion
        let imageIO = ServiceContainer.shared.imageIOService
        let imageInfo = try imageIO.getImageInfo(at: url)

        if outputFormat == .json {
            printJSON(result: result, file: url.lastPathComponent, imageInfo: imageInfo)
        } else if showHumanOutput {
            print("")
            print("âœ… Detection complete")
            print("")
            print("Heatmap: \(result.width) Ã— \(result.height)")
            print("Salient regions: \(result.salientBounds.count)")

            if !result.salientBounds.isEmpty {
                print("")
                for (index, bound) in result.salientBounds.enumerated() {
                    print("Region \(index + 1):")
                    print("  Position: (\(String(format: "%.2f", bound.origin.x)), \(String(format: "%.2f", bound.origin.y)))")
                    print("  Size: \(String(format: "%.2f", bound.width)) Ã— \(String(format: "%.2f", bound.height))")

                    // Also show pixel coordinates
                    let pixelX = Int(bound.origin.x * CGFloat(imageInfo.width))
                    let pixelY = Int((1 - bound.origin.y - bound.height) * CGFloat(imageInfo.height))
                    let pixelW = Int(bound.width * CGFloat(imageInfo.width))
                    let pixelH = Int(bound.height * CGFloat(imageInfo.height))
                    print("  Pixels: (\(pixelX), \(pixelY)) \(pixelW)Ã—\(pixelH)")
                }
            }
        }

        // Save heatmap if requested
        if let outputPath = output {
            try saveHeatmap(result: result, to: outputPath)
            if showHumanOutput {
                print("")
                print(Strings.get("info.saved_to", outputPath))
            }
        }
    }

    private func printJSON(result: VisionService.SaliencyResult, file: String, imageInfo: ImageIOService.ImageInfo) {
        let regions = result.salientBounds.map { bound -> [String: Any] in
            let pixelX = Int(bound.origin.x * CGFloat(imageInfo.width))
            let pixelY = Int((1 - bound.origin.y - bound.height) * CGFloat(imageInfo.height))
            let pixelW = Int(bound.width * CGFloat(imageInfo.width))
            let pixelH = Int(bound.height * CGFloat(imageInfo.height))

            return [
                "normalized": [
                    "x": bound.origin.x,
                    "y": bound.origin.y,
                    "width": bound.width,
                    "height": bound.height
                ],
                "pixels": [
                    "x": pixelX,
                    "y": pixelY,
                    "width": pixelW,
                    "height": pixelH
                ]
            ]
        }

        let dict: [String: Any] = [
            "file": file,
            "type": type,
            "heatmap": [
                "width": result.width,
                "height": result.height
            ],
            "salient_regions": regions
        ]

        if let jsonData = try? JSONSerialization.data(withJSONObject: dict, options: [.prettyPrinted, .sortedKeys]),
           let jsonString = String(data: jsonData, encoding: .utf8) {
            print(jsonString)
        }
    }

    private func saveHeatmap(result: VisionService.SaliencyResult, to outputPath: String) throws {
        let heatmapImage = CIImage(cvPixelBuffer: result.heatMapBuffer)

        let context = CIContext()
        #if DEBUG
        let forceNil = ProcessInfo.processInfo.environment["AIRIS_FORCE_SALIENCY_CGIMAGE_NIL"] == "1"
        let cgImageCandidate = forceNil ? nil : context.createCGImage(heatmapImage, from: heatmapImage.extent)
        #else
        let cgImageCandidate = context.createCGImage(heatmapImage, from: heatmapImage.extent)
        #endif

        guard let cgImage = cgImageCandidate else {
            throw AirisError.imageEncodeFailed
        }

        let imageIO = ServiceContainer.shared.imageIOService
        let outputURL = URL(fileURLWithPath: outputPath)

        try FileUtils.ensureDirectory(for: outputPath)

        let format = outputPath.hasSuffix(".png") ? "png" : "jpg"
        try imageIO.saveImage(cgImage, to: outputURL, format: format)
    }

    #if DEBUG
    /// æµ‹è¯•æ¡©ï¼šå¿«é€Ÿç”Ÿæˆå¸¦ 1 ä¸ªæ˜¾è‘—åŒºåŸŸçš„ 4x4 çƒ­åŠ›å›¾
    private static func testSaliencyResult(type: VisionService.SaliencyType) -> VisionService.SaliencyResult {
        let forceCreateFailure = ProcessInfo.processInfo.environment["AIRIS_FORCE_SALIENCY_TEST_PIXELBUFFER_FAIL"] == "1"

        var pixelBuffer: CVPixelBuffer?
        let status: CVReturn = forceCreateFailure
            ? kCVReturnInvalidSize
            : CVPixelBufferCreate(nil, 4, 4, kCVPixelFormatType_OneComponent8, nil, &pixelBuffer)

        let buffer: CVPixelBuffer
        if status == kCVReturnSuccess, let created = pixelBuffer {
            buffer = created
        } else {
            // ç†è®ºä¸Šä¸åº”è§¦å‘ï¼›è‹¥è§¦å‘åˆ™æŒç»­å°è¯•ç›´åˆ°åˆ›å»ºæˆåŠŸï¼ˆæµ‹è¯•æ¡©ä»…ç”¨äºè¦†ç›–ä¸é¿å… fatalErrorï¼‰ã€‚
            var retryPixelBuffer: CVPixelBuffer!
            while retryPixelBuffer == nil {
                var retryBuffer: CVPixelBuffer?
                let retryStatus = CVPixelBufferCreate(nil, 4, 4, kCVPixelFormatType_OneComponent8, nil, &retryBuffer)
                if retryStatus == kCVReturnSuccess, let retryBuffer {
                    retryPixelBuffer = retryBuffer
                }
            }
            buffer = retryPixelBuffer
        }

        let bounds: [CGRect]
        if ProcessInfo.processInfo.environment["AIRIS_TEST_SALIENCY_EMPTY"] == "1" {
            bounds = []
        } else if type == .objectness {
            bounds = [CGRect(x: 0.1, y: 0.2, width: 0.3, height: 0.4), CGRect(x: 0.6, y: 0.5, width: 0.2, height: 0.2)]
        } else {
            bounds = [CGRect(x: 0.25, y: 0.25, width: 0.5, height: 0.5)]
        }
        return VisionService.SaliencyResult(heatMapBuffer: buffer, salientBounds: bounds, width: 4, height: 4)
    }
    #endif
}
