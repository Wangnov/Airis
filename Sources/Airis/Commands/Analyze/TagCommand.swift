import ArgumentParser
@preconcurrency import Vision
import Foundation

struct TagCommand: AsyncParsableCommand {
    static let configuration = CommandConfiguration(
        commandName: "tag",
        abstract: "Classify image scenes and objects",
        discussion: """
            Identify scenes, objects, and concepts in images using Apple's \
            Vision framework.

            QUICK START:
              airis analyze tag photo.jpg

            EXAMPLES:
              # Basic classification
              airis analyze tag sunset.jpg

              # Show top 10 results with confidence > 0.1
              airis analyze tag photo.png --limit 10 --threshold 0.1

              # JSON output for scripting
              airis analyze tag image.heic --format json

              # Show all results (no threshold)
              airis analyze tag photo.jpg --threshold 0

            OUTPUT FORMAT (table):
              â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
              ğŸ·ï¸  åœºæ™¯è¯†åˆ«
              â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
              ğŸ“ æ–‡ä»¶: sunset.jpg
              ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼: 0.10
              ğŸ“Š æ˜¾ç¤ºæ•°é‡: 10
              â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

              æ£€æµ‹åˆ° 15 ä¸ªæ ‡ç­¾ï¼ˆæ˜¾ç¤ºå‰ 10 ä¸ªï¼‰

              æ ‡ç­¾                          ç½®ä¿¡åº¦
              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              sunset                        0.95
              sky                           0.92
              outdoor                       0.88
              cloud                         0.76

            OPTIONS:
              --threshold <value>   Minimum confidence (0.0-1.0, default: 0.1)
              --limit <count>       Maximum results to show (default: 20)
              --format <type>       Output format: table, json (default: table)

            NOTES:
              - Uses VNClassifyImageRequest from Apple Vision framework
              - All processing is done locally on device
              - Results are sorted by confidence (highest first)
            """
    )

    @Argument(help: "Path to the image file")
    var imagePath: String

    @Option(name: .long, help: "Minimum confidence threshold (0.0-1.0)")
    var threshold: Float = 0.1

    @Option(name: .long, help: "Maximum number of results to display")
    var limit: Int = 20

    @Option(name: .long, help: "Output format: table (default), json")
    var format: String = "table"

    func run() async throws {
        let url = try FileUtils.validateImageFile(at: imagePath)
        let vision = ServiceContainer.shared.visionService

        // æ˜¾ç¤ºå‚æ•°æ€»è§ˆ
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print("ğŸ·ï¸  åœºæ™¯è¯†åˆ«")
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print("ğŸ“ æ–‡ä»¶: \(url.lastPathComponent)")
        print("ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼: \(String(format: "%.2f", threshold))")
        print("ğŸ“Š æ˜¾ç¤ºæ•°é‡: \(limit)")
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print("")

        // æ‰§è¡Œåˆ†ç±»
#if DEBUG
        if ProcessInfo.processInfo.environment["AIRIS_FORCE_TAG_STUB"] == "1" {
            let stub = Self._testObservations(count: 5)
            handleResults(stub)
            return
        }
#endif
        let results = try await vision.classifyImage(at: url, threshold: threshold)

        handleResults(results)
    }

    private func handleResults(_ results: [VNClassificationObservation]) {
        if results.isEmpty {
            print(Strings.get("error.no_results"))
            return
        }

        // é™åˆ¶ç»“æœæ•°é‡
        let limitedResults = Array(results.prefix(limit))

        if format.lowercased() == "json" {
            printJSON(results: limitedResults, total: results.count)
        } else {
            printTable(results: limitedResults, total: results.count)
        }
    }

    private func printTable(results: [VNClassificationObservation], total: Int) {
        if results.count < total {
            print("æ£€æµ‹åˆ° \(total) ä¸ªæ ‡ç­¾ï¼ˆæ˜¾ç¤ºå‰ \(results.count) ä¸ªï¼‰")
        } else {
            print("æ£€æµ‹åˆ° \(total) ä¸ªæ ‡ç­¾")
        }
        print("")

        // è¡¨å¤´
        let headerTag = "æ ‡ç­¾"
        let headerConf = "ç½®ä¿¡åº¦"
        print("\(headerTag.padding(toLength: 30, withPad: " ", startingAt: 0))\(headerConf)")
        print(String(repeating: "â”€", count: 40))

        for observation in results {
            let identifier = observation.identifier
            let confidence = String(format: "%.2f", observation.confidence)
            print("\(identifier.padding(toLength: 30, withPad: " ", startingAt: 0))\(confidence)")
        }
    }

    private func printJSON(results: [VNClassificationObservation], total: Int) {
        let items = results.map { obs in
            [
                "identifier": obs.identifier,
                "confidence": obs.confidence
            ] as [String: Any]
        }

        let dict: [String: Any] = [
            "total_count": total,
            "displayed_count": results.count,
            "tags": items
        ]

        if let jsonData = try? JSONSerialization.data(withJSONObject: dict, options: [.prettyPrinted, .sortedKeys]),
           let jsonString = String(data: jsonData, encoding: .utf8) {
            print(jsonString)
        }
    }

    #if DEBUG
    /// æµ‹è¯•è¾…åŠ©ï¼šæ„é€ å¯æ§çš„æ ‡ç­¾åˆ—è¡¨ï¼Œä¾¿äºè¦†ç›–æ€»æ•°>æ˜¾ç¤ºæ•°çš„åˆ†æ”¯
    static func _testObservations(count: Int) -> [VNClassificationObservation] {
        (0..<count).map { idx in
            let obs = VNClassificationObservation()
            obs.setValue("tag_\(idx)", forKey: "identifier")
            obs.setValue(Float(1.0 - Double(idx) * 0.1), forKey: "confidence")
            return obs
        }
    }
    #endif
}
