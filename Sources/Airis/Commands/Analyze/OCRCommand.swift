import ArgumentParser
@preconcurrency import Vision
import Foundation

struct OCRCommand: AsyncParsableCommand {
    static let configuration = CommandConfiguration(
        commandName: "ocr",
        abstract: "Extract text from images (OCR)",
        discussion: """
            Recognize and extract text from images using Apple's Vision \
            framework. Supports multiple languages including Chinese and English.

            QUICK START:
              airis analyze ocr document.jpg

            EXAMPLES:
              # Extract text from image
              airis analyze ocr screenshot.png

              # Specify languages (Chinese + English)
              airis analyze ocr doc.jpg --languages zh-Hans,en

              # Fast mode (less accurate but faster)
              airis analyze ocr photo.png --level fast

              # JSON output for scripting
              airis analyze ocr image.heic --format json

              # Extract text with bounding boxes
              airis analyze ocr scan.jpg --show-bounds

            OUTPUT FORMAT (table):
              â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
              ğŸ“ æ–‡å­—è¯†åˆ« (OCR)
              â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
              ğŸ“ æ–‡ä»¶: document.jpg
              ğŸŒ è¯­è¨€: zh-Hans, en
              âš¡ è¯†åˆ«çº§åˆ«: accurate
              â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

              è¯†åˆ«åˆ° 5 æ®µæ–‡å­—

              [1] Hello World
              [2] ä½ å¥½ä¸–ç•Œ
              [3] Welcome to Airis
              ...

            OPTIONS:
              --languages <list>    Comma-separated language codes
                                    (default: zh-Hans,en)
              --level <mode>        Recognition level: fast, accurate
                                    (default: accurate)
              --format <type>       Output format: table, json, text
                                    (default: table)
              --show-bounds         Show bounding box coordinates

            SUPPORTED LANGUAGES:
              en (English), zh-Hans (Simplified Chinese), zh-Hant (Traditional Chinese),
              ja (Japanese), ko (Korean), de (German), fr (French), es (Spanish),
              pt (Portuguese), it (Italian), ru (Russian), and more.

            NOTES:
              - Uses VNRecognizeTextRequest from Apple Vision framework
              - All processing is done locally on device
              - 'accurate' level provides better results but is slower
              - Language correction is enabled by default
            """
    )

    @Argument(help: "Path to the image file")
    var imagePath: String

    @Option(name: .long, help: "Comma-separated language codes (default: zh-Hans,en)")
    var languages: String = "zh-Hans,en"

    @Option(name: .long, help: "Recognition level: fast, accurate (default: accurate)")
    var level: String = "accurate"

    @Option(name: .long, help: "Output format: table (default), json, text")
    var format: String = "table"

    @Flag(name: .long, help: "Show bounding box coordinates")
    var showBounds: Bool = false

    func run() async throws {
        let url = try FileUtils.validateImageFile(at: imagePath)
        let vision = ServiceContainer.shared.visionService

        // è§£æè¯­è¨€åˆ—è¡¨
        let languageList = languages.split(separator: ",").map { String($0).trimmingCharacters(in: .whitespaces) }

        // è§£æè¯†åˆ«çº§åˆ«
        let recognitionLevel: VNRequestTextRecognitionLevel = level.lowercased() == "fast" ? .fast : .accurate

        // æ˜¾ç¤ºå‚æ•°æ€»è§ˆ
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print("ğŸ“ æ–‡å­—è¯†åˆ« (OCR)")
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print("ğŸ“ æ–‡ä»¶: \(url.lastPathComponent)")
        print("ğŸŒ è¯­è¨€: \(languageList.joined(separator: ", "))")
        print("âš¡ è¯†åˆ«çº§åˆ«: \(level.lowercased())")
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print("")

        // æ‰§è¡Œ OCR
        let results = try await vision.recognizeText(
            at: url,
            languages: languageList,
            level: recognitionLevel
        )

        if results.isEmpty {
            print(Strings.get("error.no_results"))
            return
        }

        // æå–æ–‡æœ¬
        let textResults = extractTextResults(from: results)

        switch format.lowercased() {
        case "json":
            printJSON(results: textResults)
        case "text":
            printPlainText(results: textResults)
        default:
            printTable(results: textResults)
        }
    }

    private func extractTextResults(from observations: [VNRecognizedTextObservation]) -> [TextResult] {
        observations.compactMap { observation -> TextResult? in
            guard let topCandidate = observation.topCandidates(1).first else { return nil }

            let boundingBox = observation.boundingBox

            return TextResult(
                text: topCandidate.string,
                confidence: topCandidate.confidence,
                boundingBox: boundingBox
            )
        }
    }

    private func printTable(results: [TextResult]) {
        print("è¯†åˆ«åˆ° \(results.count) æ®µæ–‡å­—")
        print("")

        for (index, result) in results.enumerated() {
            print("[\(index + 1)] \(result.text)")

            if showBounds {
                let box = result.boundingBox
                let x = String(format: "%.2f", box.origin.x)
                let y = String(format: "%.2f", box.origin.y)
                let w = String(format: "%.2f", box.width)
                let h = String(format: "%.2f", box.height)
                print("    ä½ç½®: (\(x), \(y)) å¤§å°: \(w) Ã— \(h)")
            }

            // ä»…å½“ç½®ä¿¡åº¦ä½æ—¶æ˜¾ç¤º
            if result.confidence < 0.9 {
                print("    ç½®ä¿¡åº¦: \(String(format: "%.2f", result.confidence))")
            }
        }
    }

    private func printJSON(results: [TextResult]) {
        let items = results.map { result -> [String: Any] in
            var item: [String: Any] = [
                "text": result.text,
                "confidence": result.confidence
            ]

            if showBounds {
                item["bounding_box"] = [
                    "x": result.boundingBox.origin.x,
                    "y": result.boundingBox.origin.y,
                    "width": result.boundingBox.width,
                    "height": result.boundingBox.height
                ]
            }

            return item
        }

        let dict: [String: Any] = [
            "count": results.count,
            "texts": items
        ]

        if let jsonData = try? JSONSerialization.data(withJSONObject: dict, options: [.prettyPrinted, .sortedKeys]),
           let jsonString = String(data: jsonData, encoding: .utf8) {
            print(jsonString)
        }
    }

    private func printPlainText(results: [TextResult]) {
        // çº¯æ–‡æœ¬è¾“å‡ºï¼Œé€‚åˆç®¡é“å¤„ç†
        for result in results {
            print(result.text)
        }
    }

    /// OCR è¯†åˆ«ç»“æœ
    struct TextResult {
        let text: String
        let confidence: Float
        let boundingBox: CGRect
    }
}
